
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>coniii.solvers module &#8212; ConIII 1.1.9 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="coniii.samplers module" href="coniii.samplers.html" />
    <link rel="prev" title="coniii.ising.test_automaton module" href="coniii.ising.test_automaton.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-coniii.solvers">
<span id="coniii-solvers-module"></span><h1>coniii.solvers module<a class="headerlink" href="#module-coniii.solvers" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="coniii.solvers.ClusterExpansion">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">ClusterExpansion</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_size</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Implementation of Adaptive Cluster Expansion for solving the inverse Ising problem,
as described in John Barton and Simona Cocco, J. of Stat. Mech.  P03002 (2013).</p>
<p>Specific to pairwise Ising constraints.</p>
<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.S">
<code class="sig-name descname">S</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cluster</span></em>, <em class="sig-param"><span class="n">coocMat</span></em>, <em class="sig-param"><span class="n">deltaJdict</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">useAnalyticResults</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">priorLmbda</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">numSamples</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.S" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate pairwise entropy of cluster.  (First fits pairwise Ising model.)</p>
<dl class="simple">
<dt>cluster<span class="classifier">list</span></dt><dd><p>List of indices belonging to each cluster.</p>
</dd>
<dt>coocMat<span class="classifier">ndarray</span></dt><dd><p>Pairwise correlations.</p>
</dd>
</dl>
<p>deltaJdict : dict, {}
useAnalyticResults : bool, False</p>
<blockquote>
<div><p>Probably want False until analytic formulas are changed to include prior on J</p>
</div></blockquote>
<p>entropy : float
Jfull : ndarray</p>
<blockquote>
<div><p>Matrix of couplings.</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.Sindependent">
<code class="sig-name descname">Sindependent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cluster</span></em>, <em class="sig-param"><span class="n">coocMat</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.Sindependent" title="Permalink to this definition">¶</a></dt>
<dd><p>Entropy approximation assuming that each cluster appears independently of the
others.</p>
<p>cluster : list
coocMat : ndarray</p>
<blockquote>
<div><p>Pairwise correlations.</p>
</div></blockquote>
<dl class="simple">
<dt>float</dt><dd><p>Sind, independent entropy.</p>
</dd>
<dt>ndarray</dt><dd><p>Pairwise couplings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.clusterID">
<code class="sig-name descname">clusterID</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cluster</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.clusterID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.deltaS">
<code class="sig-name descname">deltaS</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cluster</span></em>, <em class="sig-param"><span class="n">coocMat</span></em>, <em class="sig-param"><span class="n">deltaSdict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">deltaJdict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">meanFieldRef</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">priorLmbda</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">numSamples</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">independentRef</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">meanFieldPriorLmbda</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.deltaS" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>cluster<span class="classifier">list </span></dt><dd><p>List of indices in cluster</p>
</dd>
</dl>
<p>coocMat : ndarray
deltaSdict : dict, None
deltaJdict : dict, None
iprint : bool, True
meanFieldRef : bool, False
numSamples : int, None
independentRef : bool, False</p>
<blockquote>
<div><p>If True, expand about independent entropy</p>
</div></blockquote>
<dl class="simple">
<dt>meanFieldRef<span class="classifier">bool, False</span></dt><dd><p>If True, expand about mean field entropy</p>
</dd>
</dl>
<dl class="simple">
<dt>float</dt><dd><p>deltaScluster</p>
</dd>
<dt>float</dt><dd><p>deltaJcluster</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">threshold</span></em>, <em class="sig-param"><span class="n">cluster</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">deltaSdict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">deltaJdict</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">priorLmbda</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">numSamples</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">meanFieldRef</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">independentRef</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">veryVerbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">meanFieldPriorLmbda</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>threshold : float
meanFieldRef : bool, False</p>
<blockquote>
<div><p>Expand about mean-field reference.</p>
</div></blockquote>
<dl class="simple">
<dt>independentRef<span class="classifier">bool, True</span></dt><dd><p>Expand about independent reference.</p>
</dd>
<dt>priorLmbda<span class="classifier">float, 0.</span></dt><dd><p>Strength of non-interacting prior.</p>
</dd>
<dt>meanFieldPriorLmbda<span class="classifier">float, None</span></dt><dd><p>Strength of non-interacting prior in mean field calculation (defaults to
priorLmbda).</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>float (optional, only if full_output=True)</dt><dd><p>Estimated entropy.</p>
</dd>
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>list (optional, only if full_output=True)</dt><dd><p>List of clusters.</p>
</dd>
<dt>dict (optional, only if full_output=True)</dt><dd><p>deltaSdict</p>
</dd>
<dt>dict (optional, only if full_output=True)</dt><dd><p>deltaJdict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.ClusterExpansion.subsets">
<code class="sig-name descname">subsets</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">thisSet</span></em>, <em class="sig-param"><span class="n">size</span></em>, <em class="sig-param"><span class="n">sort</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.subsets" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list, returns a list of all unique subsets of that list with given
size.</p>
<p>thisSet : list
size : int
sort : bool, False</p>
<dl class="simple">
<dt>list</dt><dd><p>All subsets of given size.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.Enumerate">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">Enumerate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Enumerate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving fully-connected inverse Ising model problem by enumeration of the
partition function and then using gradient descent.</p>
<dl class="py method">
<dt id="coniii.solvers.Enumerate.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_param_value</span><span class="o">=</span><span class="default_value">50</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_root</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">scipy_solver_kwargs</span><span class="o">=</span><span class="default_value">{'method': 'krylov', 'options': {'fatol': 1e-13, 'xatol': 1e-13}}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Enumerate.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Must specify either constraints (the correlations) or samples from which the
correlations will be calculated using self.calc_observables. This routine by
default uses scipy.optimize.root to find the solution. This is MUCH faster than
the scipy.optimize.minimize routine which can be used instead.</p>
<p>If still too slow, try adjusting the accuracy.</p>
<p>If not converging, try increasing the max number of iterations.</p>
<p>If receiving Jacobian error (or some other numerical estimation error), parameter
values may be too large for faithful evaluation. Try decreasing max_param_value.</p>
<dl class="simple">
<dt>initial_guess<span class="classifier">ndarray, None</span></dt><dd><p>Initial starting guess for parameters. By default, this will start with all
zeros if left unspecified.</p>
</dd>
<dt>constraints<span class="classifier">ndarray, None</span></dt><dd><p>Can specify constraints directly instead of using the ones calculated from the
sample. This can be useful when the pairwise correlations are known exactly.
This will override the self.constraints data member.</p>
</dd>
<dt>max_param_value<span class="classifier">float, 50</span></dt><dd><p>Absolute value of max parameter value. Bounds can also be set in the kwargs
passed to the minimizer, in which case this should be set to None.</p>
</dd>
<dt>full_output<span class="classifier">bool, False</span></dt><dd><p>If True, return output from scipy.optimize.minimize.</p>
</dd>
<dt>use_root<span class="classifier">bool, True</span></dt><dd><p>If False, use scipy.optimize.minimize instead. This is typically much slower.</p>
</dd>
<dt>scipy_solver_kwargs<span class="classifier">dict, {‘method’:’krylov’, ‘options’:{‘fatol’:1e-13,’xatol’:1e-13}}</span></dt><dd><p>High accuracy is slower. Although default accuracy may not be so good,
lowering these custom presets will speed things up. Choice of the root finding
method can also change runtime and whether a solution is found or not.
Recommend playing around with different solvers and tolerances or getting a
close approximation using a different method if solution is hard to find.</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>dict, optional</dt><dd><p>Output from scipy.optimize.root.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.MCH">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">MCH</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_size</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">sample_method</span><span class="o">=</span><span class="default_value">'metropolis'</span></em>, <em class="sig-param"><span class="n">mch_approximation</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sampler_kw</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving maxent problems using the Monte Carlo Histogram method.</p>
<p>Broderick, T., Dudik, M., Tkacik, G., Schapire, R. E. &amp; Bialek, W. Faster solutions of the
inverse pairwise Ising problem. arXiv 1-8 (2007).</p>
<dl class="py method">
<dt id="coniii.solvers.MCH.estimate_jac">
<code class="sig-name descname">estimate_jac</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">eps</span><span class="o">=</span><span class="default_value">0.001</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.estimate_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximation Jacobian using the MCH approximation.</p>
<p>eps : float, 1e-3</p>
<dl class="simple">
<dt>jac<span class="classifier">ndarray</span></dt><dd><p>Jacobian is an n x n matrix where each row corresponds to the behavior of fvec
wrt to a single parameter.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MCH.learn_parameters_mch">
<code class="sig-name descname">learn_parameters_mch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estConstraints</span></em>, <em class="sig-param"><span class="n">constraints</span></em>, <em class="sig-param"><span class="n">maxdlamda</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxdlamdaNorm</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxLearningSteps</span><span class="o">=</span><span class="default_value">50</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.learn_parameters_mch" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>estConstraints<span class="classifier">ndarray</span></dt><dd><p>Constraints estimated from MCH approximation.</p>
</dd>
</dl>
<p>constraints : ndarray
maxdlamda : float, 1</p>
<blockquote>
<div><p>Max allowed magnitude for any element of dlamda vector before exiting.</p>
</div></blockquote>
<dl class="simple">
<dt>maxdlamdaNorm<span class="classifier">float, 1</span></dt><dd><p>Max allowed norm of dlamda vector before exiting.</p>
</dd>
<dt>maxLearningSteps<span class="classifier">int</span></dt><dd><p>max learning steps before ending MCH</p>
</dd>
<dt>eta<span class="classifier">float, 1</span></dt><dd><p>factor for changing dlamda</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>MCH estimate for constraints from parameters lamda+dlamda.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MCH.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tolNorm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_iters</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">burn_in</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">custom_convergence_f</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">learn_params_kwargs</span><span class="o">=</span><span class="default_value">{'eta': 1, 'maxdlamda': 1}</span></em>, <em class="sig-param"><span class="n">generate_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve for maxent model parameters using MCH routine.</p>
<dl>
<dt>initial_guess<span class="classifier">ndarray, None</span></dt><dd><p>Initial starting point.</p>
</dd>
<dt>constraints<span class="classifier">ndarray, None</span></dt><dd><p>For debugging!
Vector of correlations to fit.</p>
</dd>
<dt>tol<span class="classifier">float, None</span></dt><dd><p>Maximum error allowed in any observable.</p>
</dd>
<dt>tolNorm<span class="classifier">float, None</span></dt><dd><p>Norm error allowed in found solution.</p>
</dd>
<dt>n_iters<span class="classifier">int, 30</span></dt><dd><p>Number of iterations to make between samples in MCMC sampling.</p>
</dd>
<dt>burn_in<span class="classifier">int, 30</span></dt><dd><p>Initial burn in from random sample when MC sampling.</p>
</dd>
<dt>max_iter<span class="classifier">int, 10</span></dt><dd><p>Max number of iterations of MC sampling and MCH approximation.</p>
</dd>
<dt>custom_convergence_f<span class="classifier">function, None</span></dt><dd><p>Function for determining convergence criterion. At each iteration, this
function should return the next set of learn_params_kwargs and optionally the
sample size.</p>
<p>As an example:
def learn_settings(i):</p>
<blockquote>
<div><p>‘’’
Take in the iteration counter and set the maximum change allowed in any
given parameter (maxdlamda) and the multiplicative factor eta, where 
d(parameter) = (error in observable) * eta.</p>
<p>Additional option is to also return the sample size for that step by
returning a tuple. Larger sample sizes are necessary for higher accuracy.
‘’’
if i&lt;10:</p>
<blockquote>
<div><p>return {‘maxdlamda’:1,’eta’:1}</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>return {‘maxdlamda’:.05,’eta’:.05}</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>iprint : bool, False
full_output : bool, False</p>
<blockquote>
<div><p>If True, also return the errflag and error history.</p>
</div></blockquote>
<p>learn_parameters_kwargs : dict, {‘maxdlamda’:1,’eta’:1}
generate_kwargs : dict, {}</p>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>int</dt><dd><p>Error flag.
0, converged within given criterion
1, max iterations reached</p>
</dd>
<dt>ndarray</dt><dd><p>Log of errors in matching constraints at each step of iteration.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.MCHIncompleteData">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">MCHIncompleteData</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.MCH" title="coniii.solvers.MCH"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.MCH</span></code></a></p>
<p>Class for solving maxent problems using the Monte Carlo Histogram method on
incomplete data where some spins may not be visible.</p>
<p>Broderick, T., Dudik, M., Tkacik, G., Schapire, R. E. &amp; Bialek, W. Faster
solutions of the inverse pairwise Ising problem. arXiv 1-8 (2007).</p>
<dl class="simple">
<dt>NOTE: This only works for Ising model.</dt><dd><p>Not ready for release.</p>
</dd>
</dl>
<dl class="py method">
<dt id="coniii.solvers.MCHIncompleteData.generate_sample">
<code class="sig-name descname">generate_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_iters</span></em>, <em class="sig-param"><span class="n">burn_in</span></em>, <em class="sig-param"><span class="n">uIncompleteStates</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_cond_sample_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_cond_sample_iters</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_method</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">initial_sample</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">run_regular_sampler</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">run_cond_sampler</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">disp</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">generate_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.generate_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around generate_sample_parallel() from available samplers.</p>
<p>n_iters : int
burn_in : int</p>
<blockquote>
<div><p>I think burn in is handled automatically in REMC.</p>
</div></blockquote>
<p>uIncompleteStates : list of unique states
f_cond_sample_size : lambda function</p>
<blockquote>
<div><p>Given the number of hidden spins, return the number of samples to take.</p>
</div></blockquote>
<dl class="simple">
<dt>f_cond_sample_iters<span class="classifier">lambda function</span></dt><dd><p>Given the number of hidden spins, return the number of MC iterations to make.</p>
</dd>
</dl>
<p>sample_size : int
sample_method : str
initial_sample : ndarray
generate_kwargs : dict</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MCHIncompleteData.learn_parameters_mch">
<code class="sig-name descname">learn_parameters_mch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estConstraints</span></em>, <em class="sig-param"><span class="n">fullFraction</span></em>, <em class="sig-param"><span class="n">uIncompleteStates</span></em>, <em class="sig-param"><span class="n">uIncompleteStatesCount</span></em>, <em class="sig-param"><span class="n">maxdlamda</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxdlamdaNorm</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxLearningSteps</span><span class="o">=</span><span class="default_value">50</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.learn_parameters_mch" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters with MCH step. Update is proportional to the difference between the
observables and the predicted observables after a small change to the parameters. This is
calculated from likelihood maximization, and for the incomplete data points this corresponds
to the marginal probability distribution weighted with the number of corresponding data
points.</p>
<p>estConstraints : ndarray
fullFraction : float</p>
<blockquote>
<div><p>Fraction of data points that are complete.</p>
</div></blockquote>
<dl class="simple">
<dt>uIncompleteStates<span class="classifier">list-like</span></dt><dd><p>Unique incomplete states in data.</p>
</dd>
<dt>uIncompleteStatesCount<span class="classifier">list-like</span></dt><dd><p>Frequency of each unique data point.</p>
</dd>
</dl>
<p>maxdlamda : float,1
maxdlamdaNorm : float,1
maxLearningSteps : int</p>
<blockquote>
<div><p>max learning steps before ending MCH</p>
</div></blockquote>
<dl class="simple">
<dt>eta<span class="classifier">float,1</span></dt><dd><p>factor for changing dlamda</p>
</dd>
</dl>
<p>estimatedConstraints : ndarray</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MCHIncompleteData.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">cond_sample_size</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">cond_sample_iters</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tolNorm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_iters</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">burn_in</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">disp</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">learn_params_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">generate_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve for parameters using MCH routine.</p>
<p>X                       : ndarray
constraints             : ndarray</p>
<blockquote>
<div><p>Constraints calculated from the incomplete data (accounting for missing data points).</p>
</div></blockquote>
<dl class="simple">
<dt>initial_guess<span class="classifier">ndarray=None</span></dt><dd><p>initial starting point</p>
</dd>
<dt>cond_sample_size<span class="classifier">int or function</span></dt><dd><p>Number of samples to make for conditional distribution.
If function is passed in, it will be passed number of missing spins and must return an int.</p>
</dd>
<dt>cond_sample_iters<span class="classifier">int or function</span></dt><dd><p>Number of MC iterations to make between samples.</p>
</dd>
<dt>tol<span class="classifier">float=None</span></dt><dd><p>maximum error allowed in any observable</p>
</dd>
<dt>tolNorm<span class="classifier">float</span></dt><dd><p>norm error allowed in found solution</p>
</dd>
<dt>n_iters<span class="classifier">int=30</span></dt><dd><p>Number of iterations to make between samples in MCMC sampling.</p>
</dd>
</dl>
<p>burn_in (int=30)
disp                    : int=0</p>
<blockquote>
<div><p>0, no output
1, some detail
2, most detail</p>
</div></blockquote>
<dl class="simple">
<dt>full_output<span class="classifier">bool,False</span></dt><dd><p>Return errflag and errors at each iteration if True.</p>
</dd>
</dl>
<p>learn_parameters_kwargs : dict
generate_kwargs         : dict</p>
<dl class="simple">
<dt>parameters<span class="classifier">ndarray</span></dt><dd><p>Found solution.</p>
</dd>
</dl>
<p>errflag : int
errors : ndarray</p>
<blockquote>
<div><p>Errors in matching constraints at each step of iteration.</p>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.MPF">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">MPF</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_de</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">adj</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<dl class="py method">
<dt id="coniii.solvers.MPF.K">
<code class="sig-name descname">K</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xuniq</span></em>, <em class="sig-param"><span class="n">Xcount</span></em>, <em class="sig-param"><span class="n">adjacentStates</span></em>, <em class="sig-param"><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.K" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective function.</p>
<dl class="simple">
<dt>Xuniq<span class="classifier">ndarray</span></dt><dd><p>(ndata x ndims)
unique states that appear in the data</p>
</dd>
<dt>Xcount<span class="classifier">ndarray of int</span></dt><dd><p>number of times that each unique state appears in the data</p>
</dd>
<dt>adjacentStates<span class="classifier">list of ndarray</span></dt><dd><p>list of adjacent states for each given unique state</p>
</dd>
<dt>params<span class="classifier">ndarray</span></dt><dd><p>parameters for computation of energy</p>
</dd>
</dl>
<p>K : float</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MPF.list_adjacent_states">
<code class="sig-name descname">list_adjacent_states</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xuniq</span></em>, <em class="sig-param"><span class="n">all_connected</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.list_adjacent_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Use self.adj to evaluate all adjacent states in Xuniq.</p>
<p>Xuniq : ndarray
all_connected : bool</p>
<p>adjacentStates</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MPF.logK">
<code class="sig-name descname">logK</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xuniq</span></em>, <em class="sig-param"><span class="n">Xcount</span></em>, <em class="sig-param"><span class="n">adjacentStates</span></em>, <em class="sig-param"><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.logK" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute log of objective function.</p>
<dl class="simple">
<dt>Xuniq<span class="classifier">ndarray</span></dt><dd><p>(n_samples, n_dim)
unique states that appear in the data</p>
</dd>
<dt>Xcount<span class="classifier">ndarray of int</span></dt><dd><p>number of times that each unique state appears in the data</p>
</dd>
<dt>adjacentStates<span class="classifier">list of ndarray</span></dt><dd><p>list of adjacent states for each given unique state</p>
</dd>
<dt>params<span class="classifier">ndarray</span></dt><dd><p>parameters for computation of energy</p>
</dd>
</dl>
<p>logK : float</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MPF.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'L-BFGS-B'</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">all_connected</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">parameter_limits</span><span class="o">=</span><span class="default_value">100</span></em>, <em class="sig-param"><span class="n">solver_kwargs</span><span class="o">=</span><span class="default_value">{'disp': False, 'ftol': 1e-15, 'maxiter': 100}</span></em>, <em class="sig-param"><span class="n">uselog</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize MPF objective function using scipy.optimize.minimize.</p>
<p>initial_guess : ndarray, None
method : str, ‘L-BFGS-B’</p>
<blockquote>
<div><p>Option for scipy.optimize.minimize.</p>
</div></blockquote>
<p>full_output : bool, False
all_connected : bool, True</p>
<blockquote>
<div><p>Switch for summing over all states that data sets could be connected to or
just summing over non-data states (second summation in Eq 10 in Sohl-Dickstein
2011).</p>
</div></blockquote>
<dl class="simple">
<dt>parameter_limits<span class="classifier">float, 100</span></dt><dd><p>Maximum allowed magnitude of any single parameter.</p>
</dd>
<dt>solver_kwargs<span class="classifier">dict, {‘maxiter’:100,’disp’:False,’ftol’:1e-15}</span></dt><dd><p>For scipy.optimize.minimize.</p>
</dd>
<dt>uselog<span class="classifier">bool, True</span></dt><dd><p>If True, calculate log of the objective function. This can help with numerical
precision errors.</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>dict (optional)</dt><dd><p>Output from scipy.optimize.minimize returned if full_output is True.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.MPF.worker_objective_task">
<em class="property">static </em><code class="sig-name descname">worker_objective_task</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s</span></em>, <em class="sig-param"><span class="n">Xcount</span></em>, <em class="sig-param"><span class="n">adjacentStates</span></em>, <em class="sig-param"><span class="n">params</span></em>, <em class="sig-param"><span class="n">calc_e</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.worker_objective_task" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py attribute">
<dt id="coniii.solvers.MonteCarloHistogram">
<code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">MonteCarloHistogram</code><a class="headerlink" href="#coniii.solvers.MonteCarloHistogram" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#coniii.solvers.MCH" title="coniii.solvers.MCH"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.MCH</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.Pseudo">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">Pseudo</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">get_multipliers_r</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables_r</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">k</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Pseudolikelihood approximation to solving the inverse Ising problem as described in
Aurell and Ekeberg, PRL 108, 090201 (2012).</p>
<dl class="py method">
<dt id="coniii.solvers.Pseudo.cond_hess">
<code class="sig-name descname">cond_hess</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">r</span></em>, <em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Jr</span></em>, <em class="sig-param"><span class="n">pairCoocRhat</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_hess" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns d^2 cond_log_likelihood / d Jri d Jrj, with shape (dimension of
system)x(dimension of system)</p>
<p>Current implementation uses more memory for speed.  For large sample size, it may
make sense to break up differently if too much memory is being used.</p>
<p>Deprecated.</p>
<dl class="simple">
<dt>pairCooc<span class="classifier">ndarray, None</span></dt><dd><p>Pass pair_cooc_mat(X) to speed calculation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Pseudo.cond_jac">
<code class="sig-name descname">cond_jac</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">r</span></em>, <em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Jr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns d cond_log_likelihood / d Jr, with shape (dimension of system)</p>
<p>Deprecated.</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Pseudo.cond_log_likelihood">
<code class="sig-name descname">cond_log_likelihood</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">r</span></em>, <em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">Jr</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Equals the conditional log likelihood -L_r.</p>
<p>Deprecated.</p>
<dl class="simple">
<dt>r<span class="classifier">int</span></dt><dd><p>individual index</p>
</dd>
<dt>X<span class="classifier">ndarray</span></dt><dd><p>binary matrix, (# X) x (dimension of system)</p>
</dd>
<dt>Jr<span class="classifier">ndarray</span></dt><dd><p>(dimension of system) x (1)</p>
</dd>
</dl>
<p>float</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Pseudo.pair_cooc_mat">
<code class="sig-name descname">pair_cooc_mat</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.pair_cooc_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns matrix of shape (self.n)x(# X)x(self.n).</p>
<p>For use with cond_hess.</p>
<p>Slow because I haven’t thought of a better way of doing it yet.</p>
<p>Deprecated.</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Pseudo.pseudo_log_likelihood">
<code class="sig-name descname">pseudo_log_likelihood</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">J</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.pseudo_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>TODO: Could probably be made more efficient.</p>
<p>Deprecated.</p>
<dl class="simple">
<dt>X<span class="classifier">ndarray</span></dt><dd><p>binary matrix, (# of samples) x (dimension of system)</p>
</dd>
<dt>J<span class="classifier">ndarray</span></dt><dd><p>(dimension of system) x (dimension of system)
J should be symmetric</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Pseudo.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">force_general</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses a general all-purpose optimization to solve the problem using functions
defined in self.get_multipliers_r and self.calc_observables_r.</p>
<dl class="simple">
<dt>force_general<span class="classifier">bool, False</span></dt><dd><p>If True, force use of “general” algorithm.</p>
</dd>
<dt>initial_guess<span class="classifier">ndarray, None</span></dt><dd><p>Initial guess for the parameter values.</p>
</dd>
<dt>solver_kwargs<span class="classifier">dict, {}</span></dt><dd><p>kwargs for scipy.minimize().</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.RegularizedMeanField">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">RegularizedMeanField</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_size</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Implementation of regularized mean field method for solving the inverse Ising
problem, as described in Daniels, Bryan C., David C. Krakauer, and Jessica C. Flack.
<a href="#system-message-1"><span class="problematic" id="problematic-1">``</span></a>Control of Finite Critical Behaviour in a Small-Scale Social System.’’ Nature
Communications 8 (2017): 14301.  doi:10.1038/ncomms14301</p>
<p>Specific to pairwise Ising constraints.</p>
<dl class="py method">
<dt id="coniii.solvers.RegularizedMeanField.bracket1d">
<code class="sig-name descname">bracket1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xList</span></em>, <em class="sig-param"><span class="n">funcList</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField.bracket1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Assumes xList is monotonically increasing</p>
<p>Get bracketed interval (a,b,c) with a &lt; b &lt; c, and f(b) &lt; f(a) and f(c).
(Choose b and c to make f(b) and f(c) as small as possible.)</p>
<p>If minimum is at one end, raise error.</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.RegularizedMeanField.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_grid_points</span><span class="o">=</span><span class="default_value">200</span></em>, <em class="sig-param"><span class="n">min_size</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">reset_rng</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">min_covariance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">min_independent</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">cooc_cov</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">priorLmbda</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">bracket</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Varies the strength of regularization on the mean field J to best fit given
cooccurrence data.</p>
<dl class="simple">
<dt>n_grid_points<span class="classifier">int, 200</span></dt><dd><p>If bracket is given, first test at n_grid_points points evenly spaced in the
bracket interval, then give the lowest three points to
scipy.optimize.minimize_scalar</p>
</dd>
<dt>min_size<span class="classifier">int, 0</span></dt><dd><p>Use a modified model in which samples with fewer ones than min_size are not
allowed.</p>
</dd>
<dt>reset_rng: bool, True</dt><dd><p>Reset random number generator seed before sampling to ensure that objective
function does not depend on generator state.</p>
</dd>
<dt>min_covariance<span class="classifier">bool, False</span></dt><dd><p>** As of v1.0.3, not currently supported **
Minimize covariance from emperical frequencies (see notes); trying to avoid
biases, as inspired by footnote 12 in TkaSchBer06</p>
</dd>
<dt>min_independent<span class="classifier">bool, True</span></dt><dd><p>** As of v1.0.3, min_independent is the only mode currently supported **
Each &lt;xi&gt; and &lt;xi xj&gt; residual is treated as independent</p>
</dd>
<dt>cooc_cov<span class="classifier">ndarray, None</span></dt><dd><p>** As of v1.0.3, not currently supported **
Provide a covariance matrix for residuals.  Should typically be
coocSampleCovariance(samples).  Only used if min_covariance and
min_independent are False.</p>
</dd>
<dt>priorLmbda<span class="classifier">float,0.</span></dt><dd><p>** As of v1.0.3, not currently implemented **
Strength of noninteracting prior.</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.Solver">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">Solver</code><a class="headerlink" href="#coniii.solvers.Solver" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Base class for declaring common methods and attributes for inverse maxent
algorithms.</p>
<dl class="py method">
<dt id="coniii.solvers.Solver.basic_setup">
<code class="sig-name descname">basic_setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample_or_n</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">model_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.basic_setup" title="Permalink to this definition">¶</a></dt>
<dd><p>General routine for setting up a Solver instance.</p>
<dl>
<dt>sample_or_n<span class="classifier">ndarray or int, None</span></dt><dd><p>If ndarray, of dimensions (samples, dimension).</p>
<p>If int, specifies system size.</p>
<p>If None, many of the default class members cannot be set and then must be set
manually.</p>
</dd>
<dt>model<span class="classifier">class like one from models.py, None</span></dt><dd><p>By default, will be set to solve Ising model.</p>
</dd>
<dt>calc_observables<span class="classifier">function, None</span></dt><dd><p>For calculating observables from a set of samples.</p>
</dd>
<dt>iprint<span class="classifier">str, True</span></dt><dd><p>If empty, do not display warning messages.</p>
</dd>
<dt>model_kwargs<span class="classifier">dict, {}</span></dt><dd><p>Additional arguments that will be passed to Ising class. These only matter if
model is None. Important ones include “n_cpus” and “rng”.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Solver.fill_in">
<code class="sig-name descname">fill_in</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">fill_value</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.fill_in" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function for filling in missing parameter values.</p>
<p>x : ndarray
fill_value : float, 0</p>
<dl class="simple">
<dt>ndarray</dt><dd><p>With missing entries filled in.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Solver.logp">
<code class="sig-name descname">logp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">run_checks</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.logp" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate log likelihood of given set of states using self.model.sample.</p>
<dl class="simple">
<dt>sample<span class="classifier">ndarray, None</span></dt><dd><p>Sample of states for which to estimate log likelihood. Default is to use
self.sample.</p>
</dd>
</dl>
<p>run_checks : bool, True</p>
<p>ndarray</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Solver.set_insertion_ix">
<code class="sig-name descname">set_insertion_ix</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.set_insertion_ix" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate indices to fill in with zeros to “fool” code that takes full set of
params.</p>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.Solver.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>To be defined in derivative classes.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.SparseEnumerate">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">SparseEnumerate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">parameter_ix</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.SparseEnumerate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving Ising model with a sparse parameter set by enumeration of
the partition function and then using gradient descent. Unspecified parameters are
implicitly fixed to be zero, which corresponds to leaving the corresponding
correlation function unconstrained.</p>
<dl class="py method">
<dt id="coniii.solvers.SparseEnumerate.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">max_param_value</span><span class="o">=</span><span class="default_value">50</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">use_root</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">scipy_solver_kwargs</span><span class="o">=</span><span class="default_value">{'method': 'krylov', 'options': {'fatol': 1e-13, 'xatol': 1e-13}}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.SparseEnumerate.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Must specify either constraints (the correlations) or samples from which the
correlations will be calculated using self.calc_observables. This routine by
default uses scipy.optimize.root to find the solution. This is MUCH faster than
the scipy.optimize.minimize routine which can be used instead.</p>
<p>If still too slow, try adjusting the accuracy.</p>
<p>If not converging, try increasing the max number of iterations.</p>
<p>If receiving Jacobian error (or some other numerical estimation error), parameter
values may be too large for faithful evaluation. Try decreasing max_param_value.</p>
<dl class="simple">
<dt>initial_guess<span class="classifier">ndarray, None</span></dt><dd><p>Initial starting guess for parameters. By default, this will start with all
zeros if left unspecified.</p>
</dd>
<dt>constraints<span class="classifier">ndarray, None</span></dt><dd><p>Can specify constraints directly instead of using the ones calculated from the
sample. This can be useful when the pairwise correlations are known exactly.
This will override the self.constraints data member.</p>
</dd>
<dt>max_param_value<span class="classifier">float, 50</span></dt><dd><p>Absolute value of max parameter value. Bounds can also be set in the kwargs
passed to the minimizer, in which case this should be set to None.</p>
</dd>
<dt>full_output<span class="classifier">bool, False</span></dt><dd><p>If True, return output from scipy.optimize.minimize.</p>
</dd>
<dt>use_root<span class="classifier">bool, True</span></dt><dd><p>If False, use scipy.optimize.minimize instead. This is typically much slower.</p>
</dd>
<dt>scipy_solver_kwargs<span class="classifier">dict, {‘method’:’krylov’, ‘options’:{‘fatol’:1e-13,’xatol’:1e-13}}</span></dt><dd><p>High accuracy is slower. Although default accuracy may not be so good,
lowering these custom presets will speed things up. Choice of the root finding
method can also change runtime and whether a solution is found or not.
Recommend playing around with different solvers and tolerances or getting a
close approximation using a different method if solution is hard to find.</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters).</p>
</dd>
<dt>dict, optional</dt><dd><p>Output from scipy.optimize.root.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="coniii.solvers.SparseMCH">
<em class="property">class </em><code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">SparseMCH</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sample</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calc_observables</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sample_size</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">sample_method</span><span class="o">=</span><span class="default_value">'metropolis'</span></em>, <em class="sig-param"><span class="n">mch_approximation</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">parameter_ix</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sampler_kw</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">default_model_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.SparseMCH" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal notranslate"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving maxent problems on sparse constraints using the Monte Carlo
Histogram method.</p>
<p>See MCH class.</p>
<dl class="py method">
<dt id="coniii.solvers.SparseMCH.learn_parameters_mch">
<code class="sig-name descname">learn_parameters_mch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estConstraints</span></em>, <em class="sig-param"><span class="n">constraints</span></em>, <em class="sig-param"><span class="n">maxdlamda</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxdlamdaNorm</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">maxLearningSteps</span><span class="o">=</span><span class="default_value">50</span></em>, <em class="sig-param"><span class="n">eta</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.SparseMCH.learn_parameters_mch" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>estConstraints<span class="classifier">ndarray</span></dt><dd><p>Constraints estimated from MCH approximation.</p>
</dd>
</dl>
<p>constraints : ndarray
maxdlamda : float, 1</p>
<blockquote>
<div><p>Max allowed magnitude for any element of dlamda vector before exiting.</p>
</div></blockquote>
<dl class="simple">
<dt>maxdlamdaNorm<span class="classifier">float, 1</span></dt><dd><p>Max allowed norm of dlamda vector before exiting.</p>
</dd>
<dt>maxLearningSteps<span class="classifier">int</span></dt><dd><p>max learning steps before ending MCH</p>
</dd>
<dt>eta<span class="classifier">float, 1</span></dt><dd><p>factor for changing dlamda</p>
</dd>
</dl>
<dl class="simple">
<dt>ndarray</dt><dd><p>MCH estimate for constraints from parameters lamda+dlamda.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="coniii.solvers.SparseMCH.solve">
<code class="sig-name descname">solve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initial_guess</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">constraints</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tolNorm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_iters</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">burn_in</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">maxiter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">custom_convergence_f</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iprint</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">full_output</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">learn_params_kwargs</span><span class="o">=</span><span class="default_value">{'eta': 1, 'maxdlamda': 1}</span></em>, <em class="sig-param"><span class="n">generate_kwargs</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.SparseMCH.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve for maxent model parameters using MCH routine.</p>
<dl>
<dt>initial_guess<span class="classifier">ndarray, None</span></dt><dd><p>Initial starting point.</p>
</dd>
<dt>constraints<span class="classifier">ndarray, None</span></dt><dd><p>For debugging!
Vector of correlations to fit.</p>
</dd>
<dt>tol<span class="classifier">float, None</span></dt><dd><p>Maximum error allowed in any observable.</p>
</dd>
<dt>tolNorm<span class="classifier">float, None</span></dt><dd><p>Norm error allowed in found solution.</p>
</dd>
<dt>n_iters<span class="classifier">int, 30</span></dt><dd><p>Number of iterations to make between samples in MCMC sampling.</p>
</dd>
<dt>burn_in<span class="classifier">int, 30</span></dt><dd><p>Initial burn in from random sample when MC sampling.</p>
</dd>
<dt>max_iter<span class="classifier">int, 10</span></dt><dd><p>Max number of iterations of MC sampling and MCH approximation.</p>
</dd>
<dt>custom_convergence_f<span class="classifier">function, None</span></dt><dd><p>Function for determining convergence criterion. At each iteration, this
function should return the next set of learn_params_kwargs and optionally the
sample size.</p>
<p>As an example:
def learn_settings(i):</p>
<blockquote>
<div><p>‘’’
Take in the iteration counter and set the maximum change allowed in any
given parameter (maxdlamda) and the multiplicative factor eta, where 
d(parameter) = (error in observable) * eta.</p>
<p>Additional option is to also return the sample size for that step by
returning a tuple. Larger sample sizes are necessary for higher accuracy.
‘’’
if i&lt;10:</p>
<blockquote>
<div><p>return {‘maxdlamda’:1,’eta’:1}</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>return {‘maxdlamda’:.05,’eta’:.05}</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>iprint : bool, False
full_output : bool, False</p>
<blockquote>
<div><p>If True, also return the errflag and error history.</p>
</div></blockquote>
<p>learn_parameters_kwargs : dict, {‘maxdlamda’:1,’eta’:1}
generate_kwargs : dict, {}</p>
<dl class="simple">
<dt>ndarray</dt><dd><p>Solved multipliers (parameters). For Ising problem, these can be converted
into matrix format using utils.vec2mat.</p>
</dd>
<dt>int</dt><dd><p>Error flag.
0, converged within given criterion
1, max iterations reached</p>
</dd>
<dt>ndarray</dt><dd><p>Log of errors in matching constraints at each step of iteration.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="coniii.solvers.unwrap_self_worker_obj">
<code class="sig-prename descclassname">coniii.solvers.</code><code class="sig-name descname">unwrap_self_worker_obj</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arg</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwarg</span></em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.unwrap_self_worker_obj" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">ConIII</a></h1>








<h3>Navigation</h3>
<p><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="coniii.enumerate.html">coniii.enumerate module</a></li>
<li class="toctree-l1"><a class="reference internal" href="coniii.enumerate_potts.html">coniii.enumerate_potts module</a></li>
<li class="toctree-l1"><a class="reference internal" href="coniii.ising.html">coniii.ising package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">coniii.solvers module</a></li>
<li class="toctree-l1"><a class="reference internal" href="coniii.samplers.html">coniii.samplers module</a></li>
<li class="toctree-l1"><a class="reference internal" href="coniii.utils.html">coniii.utils module</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="coniii.ising.test_automaton.html" title="previous chapter">coniii.ising.test_automaton module</a></li>
      <li>Next: <a href="coniii.samplers.html" title="next chapter">coniii.samplers module</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Edward D. Lee, Bryan C. Daniels.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.0.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/coniii_rst/coniii.solvers.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>